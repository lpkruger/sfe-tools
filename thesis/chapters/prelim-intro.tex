
\chapter{Introduction}
\begin{quote}
%
\begin{comment}
\begin{quote}
As every man goes through life he fills in a number of forms for the
record, each containing a number of questions... There are thus hundreds
of little threads radiating from every man, millions of threads in
all. If these threads were suddenly to become visible, the whole sky
would look like a spider's web, and if they materialized as rubber
bands, buses; trams and even people would all lose the ability to
move, and the wind would be unable to carry torn-up newspapers or
autumn leaves along the streets of the city. They are not visible,
they are not material, but every man is constantly aware of their
existence.... Each man, permanently aware of his own invisible threads,
naturally develops a respect for the people who manipulate the threads.

--Alexander Solzhenitsyn, Cancer Ward, 1968.
\end{quote}

\end{comment}
{}
\end{quote}
Privacy and security are important concerns as computers increase
in power and the Internet continues to grow \cite{cra99,tur03}. Everyday
activities dealing with sensitive data are moving onto to the Internet,
such as credit card transactions, doctors accessing medical records,
and online banking. As a result, more data is stored on machines that
are connected to the Internet, directly or indirectly, then ever before.
Sadly, there are many all-too-common examples in the newspapers of
privacy compromising activities such as phishing, data theft, and
identity theft. New techniques are needed to deal with the many threats
to privacy. In addition to the misuse of data, there can be other
consequences of privacy violations, such as serious legal penalties
for violation of HIPAA laws \cite{hippa}, which mandate strict privacy
requirements among health-care professionals.

Despite these many privacy concerns, there is also a conflicting desire
to perform useful computations with such data. Data is not useful
unless it can be accessed and manipulated. Sometimes various parties
would like to collaborate on research involving sensitive data. For
example, genetic data is the subject of much current research, but
it is considered private personal information. Researchers with access
to different patients' data may want to combine their information
resources in the search for new cures for diseases, yet not reveal
the actual sensitive information to the collaborating parties. Competing
businesses may want to jointly perform market research for mutual
benefit, without exposing their sensitive business data. The challenge
is how to balance these competing concerns, making data available
for desirable uses while preserving as much privacy as possible. If
this balance can be achieved, new uses of data may become possible
which would be otherwise impossible without strong privacy guarantees.

These concerns are not merely theoretical. In 2000, Ford Motor Explorer
SUVs had a well publicized problem with their Firestone tires, in
which the tire treads could fail under certain circumstances. At least
271 deaths resulted \cite{NYTFordFirestone}. The problem resulted
from the \emph{combination} of products: There were no problems with
the same tires in other vehicles, nor with Ford Explorers using other
tires. It has been suggested that the crisis could have been averted
using joint data-mining, however, due to business secrecy concerns,
such research could only have been done using privacy preserving methods
\cite{VaidyaClifton:2002}.

There have been several methods developed so far for preserving personal
privacy while permitting use of data. The most simple method, conceptually,
is to replace identifying information, such as the name, social security
number, and other sensitive data with random unique identifiers, and
then using the transformed data for computation. If it is necessary
to correlate the outputs of the computation with individuals, the
data owner can do this, but other parties presumably can not. However,
this method has been shown to be vulnerable to attacks that correlate
the transformed data with information available from external sources
to reconstruct the obfuscated data, thereby breaking the privacy protection
\cite{Malin04}. 

Another method of preserving privacy is known as \emph{secure multiparty
computation}. This is a technique of performing computations on inputs
supplied by multiple parties while provably maintaining privacy guarantees.
If the computation is a function evaluation, then it is called \emph{secure
function evaluation}, or SFE. This is a technique which can address
many of the privacy concerns facing the modern age. The inputs to
the function are partitioned among more than one party, and the function
is computed collaboratively while preserving the privacy of each participant's
individual inputs. In this case, privacy is considered preserved if
no party learns any information that would affect their estimate of
the probability distribution of another party's inputs, except for
that which can be calculated by the parties' own inputs and the output
of the joint function. In comparison with other methods, only secure
multiparty computation can be used to guarantee privacy when parties
collaborate on joint computation. %
\begin{comment}
%
\begin{lyxgreyedout}
Needs clarification
\end{lyxgreyedout}
 In other words, the entropy gain of each party is equivalent to the
entropy gain in an idealized protocol where a trusted third party
collects all the inputs, evaluates the function, and transmits only
the output to each party. Depending on the protocol, the guarantees
for some parties may be based on typical assumptions of computational
hardness, while the guarantees for other parties may be information
theoretic.
\end{comment}
{}

Although SFE has provable privacy guarantees, its implementation tends
to be very expensive for practical use in terms of time and space.
The space expense manifests itself in the large consumption of network
bandwidth used in the protocols, and the time expense comes from repeated
use of expensive cryptographic primitives, such as modular exponentiation.
These expenses explain why SFE has not been used very much outside
of the academic literature, despite the fact that it was formally
introduced many years ago, in the early 1980s \cite{Y82}. There has
been research in recent years to make SFE more practical. This research
falls into two categories: general and function specific. General
protocols allow any function expressed as a circuit computation to
be evaluated securely. The Fairplay system \cite{Fairplay} is a straightforward
implementation of the Yao protocol \cite{Yao86}, presented in section
\ref{sub:Garbled-Circuit-Method}, along with a supporting compiler
that allows secure functions to be written in a more familiar functional
programming notation. Kruger \emph{et al.} \cite{kruger06} showed
how \emph{Ordered Binary Decision Diagrams} (OBDD) can be used to
produce a more efficient protocol for secure evaluation for certain
functions. Function specific protocol design has produced secure protocols
which perform dramatically better than general protocols. Privacy
preserving data mining (PPDM) has been a major application driving
such research \cite{verykios04stateart}. Other protocols have been
developed for various classes of functions such as polynomial evaluation
\cite{naor99otope} and string alignment algorithms such as edit distance
\cite{kruger07}. Also, the amount of time required for the computations
has benefited greatly from Moore's law. I have shown that in some
simple cases, the computation requirements of the most general protocols
can be adequate for practical use when performed on today's fastest
CPUs \cite{kruger06}.

I propose to research ways to improve the efficiency and practicality
of privacy preserving protocols. My past work has investigated finding
efficient protocols for specific classes of functions, in particular,
one study analyzes several designs of a $k$-means clustering algorithm
\cite{kruger05}, and another discusses ways to design efficient protocols
for many kinds of dynamic programming problems \cite{kruger07}. I
have also investigated the use of alternate circuit representations
using OBDDs to improve the performance of general purpose protocols
and showed that they can be beneficial for certain functions \cite{kruger06}.
These works are discussed in section \ref{sec:Techniques}.

I am proposing to continue the work suggested by these initial studies,
and further investigate ways to improve the performance and simplify
the task of constructing efficient privacy preserving protocols, culminating
in an optimizing protocol compiler. In addition to the research results,
I also plan to release the SFE compiler and supporting tools as a
stimulus to expand future research in secure function evaluation.

Specifically, I propose that my work will create the following contributions:
\begin{itemize}
\item \emph{Protocols for other alternative representation of circuits}.
Although my work with OBDDs showed improved performance with certain
functions, OBDDs exhibit exponential blowup in many circuits of practical
interest such as multiplication. There have been many generalizations
of OBDDs intended to address these problems. An arithmetic-focused
approach has been to extend OBDDs from the Boolean domain to the numeric
domain, such as in \emph{binary moment diagrams} \cite{bryant94verification}
and \emph{hybrid decision} \emph{diagrams} \cite{clarke95hybrid}.
Another approach, \emph{binary expression diagrams} \cite{BoolExprDiagram},
have composed BDD-style decision nodes with Boolean gates in the same
circuit. I will research whether these alternate circuit representations
can yield efficient protocols for general purpose secure function
evaluation.
\item \emph{Protocols for evaluating functions with controlled leakage of
information}. The traditional definition of secure function evaluation
allows the parties to learn their designated outputs and no additional
information. In ordinary (non-secure) computation, the parties learn
all information. Intuitively, these are the extreme ends of a continuum
of information learned. Since the overhead of privacy protection is
substantial, the question I will research is how can secure protocols
be designed at intermediate points in the continuum, where some but
not all privacy is guaranteed. For example, if a Boolean circuit can
be partitioned into \emph{sensitive} and \emph{non-sensitive} gates,
what quantity of performance gain can be achieved by allowing the
non-sensitive information to be revealed?
\item \emph{A compiler for creating efficient secure evaluation protocols.}
Fairplay \cite{Fairplay} is the first attempt to create a general
purpose secure protocol compiler. It works in a straightforward way,
by converting a functional language into a Boolean circuit and executing
a generic protocol to evaluate it. However, this straightforward approach
is not efficient enough for practical use in all but the simplest
circuits. I plan to integrate the various techniques I have researched
to create the first optimizing protocol compiler for secure function
evaluation.
\item \emph{Examples showing that SFE can be useful in other aspects of
security where it has not previously been used}. Specifically, I will
show how SFE can be used to implement a more secure authentication
protocol in SSH.
\end{itemize}

