
\chapter{Introduction}
\begin{quote}
%
\begin{comment}
\begin{quote}
As every man goes through life he fills in a number of forms for the
record, each containing a number of questions... There are thus hundreds
of little threads radiating from every man, millions of threads in
all. If these threads were suddenly to become visible, the whole sky
would look like a spider's web, and if they materialized as rubber
bands, buses; trams and even people would all lose the ability to
move, and the wind would be unable to carry torn-up newspapers or
autumn leaves along the streets of the city. They are not visible,
they are not material, but every man is constantly aware of their
existence.... Each man, permanently aware of his own invisible threads,
naturally develops a respect for the people who manipulate the threads.

--Alexander Solzhenitsyn, Cancer Ward, 1968.
\end{quote}

\end{comment}
{}
\end{quote}
Privacy and security are important concerns as computers increase
in power and the Internet continues to grow \cite{cra99,tur03}. Everyday
activities dealing with sensitive data are moving onto to the Internet,
such as credit card transactions, doctors accessing medical records,
and online banking. As a result, more data is stored on machines that
are connected to the Internet, directly or indirectly, then ever before.
Sadly, there are many all-too-common examples in the news of
privacy compromising activities such as phishing, data theft, and
identity theft. New techniques are needed to deal with the many threats
to privacy. In addition to the misuse of data, there can be other
consequences of privacy violations, such as serious legal penalties
for violation of HIPAA laws \cite{hippa}, which mandate strict privacy
requirements among health-care professionals.

Despite these many privacy concerns, there is also a conflicting desire
to perform useful computations with sensitive data. Data is not useful
unless it can be accessed and manipulated. Sometimes various parties
would like to collaborate on research involving this data. For
example, genetic data is the subject of much current research, but
it is considered private personal information. Researchers with access
to different patients' data may want to combine their information
resources in the search for new cures for diseases, without revealing
the actual sensitive information to the collaborating parties. Competing
businesses may want to jointly perform market research for mutual
benefit, without exposing their sensitive business data. Therefore,
the challenge
is how to balance these competing concerns, making data available
for desirable uses while preserving as much privacy as possible.  By
providing strong privacy guarentees, we enable new uses of sensitive data.

These concerns are not merely theoretical. In 2000, Ford Motor Explorer
SUVs had a well publicized problem with their Firestone tires, in
which the tire treads could fail under certain circumstances. At least
271 deaths resulted \cite{NYTFordFirestone}. The problem resulted
from the \emph{combination} of products: There were no problems with
the same tires in other vehicles, nor with Ford Explorers using other
tires. It has been suggested that the crisis could have been averted
using joint data-mining, however, due to business secrecy concerns,
such research could only have been done using privacy preserving methods
\cite{VaidyaClifton:2002}.

There have been several methods developed so far for preserving personal
privacy while permitting use of data. The most simple method, conceptually,
is to replace identifying information, such as the name, social security
number, and other sensitive data with random unique identifiers, and
then using the transformed data for computation. If it is necessary
to correlate the outputs of the computation with individuals, the
data owner can do this, but other parties presumably can not. However,
this method has been shown to be vulnerable to attacks that correlate
the transformed data with information available from external sources
to reconstruct the obfuscated data, thereby breaking the privacy protection
\cite{Malin04}. 

Another method for preserving privacy is known as \emph{secure multiparty
computation}\cite{Yao86}. This is a technique of performing computations on inputs
supplied by multiple parties while provably maintaining privacy guarantees.
If the computation is a function evaluation, then it is called \emph{secure
function evaluation}, or SFE. This is a technique which in theory can address
many of the privacy concerns we face. The inputs to
the function are partitioned among more than one party, and the function
is computed collaboratively while preserving the privacy of each participant's
individual inputs. In this case, privacy is considered preserved if
no party learns any information that would affect their estimate of
the probability distribution of another party's inputs, except for
that which can be calculated by the parties' own inputs and the output
of the joint function. In comparison with other methods, only secure
multiparty computation can be used to guarantee privacy when parties
collaborate on joint computation. %
\begin{comment}
%
\begin{lyxgreyedout}
Needs clarification
\end{lyxgreyedout}
 In other words, the entropy gain of each party is equivalent to the
entropy gain in an idealized protocol where a trusted third party
collects all the inputs, evaluates the function, and transmits only
the output to each party. Depending on the protocol, the guarantees
for some parties may be based on typical assumptions of computational
hardness, while the guarantees for other parties may be information
theoretic.
\end{comment}
{}

Although SFE has provable privacy guarantees, its implementation tends
to be very expensive for practical use in terms of time and space.
The space expense manifests itself in the large consumption of network
bandwidth used in the protocols, and the time expense comes from repeated
use of expensive cryptographic primitives, such as modular exponentiation.
These expenses explain why SFE has not been frequently used outside
of the academic literature, despite the fact that it was formally
introduced in the literature in the early 1980s \cite{Y82}. There has
been research in recent years to make SFE more practical. This research
falls into two categories: general and function specific. General
protocols allow any function expressed as a circuit computation to
be evaluated securely. The Fairplay system \cite{Fairplay} is a straightforward
implementation of the Yao protocol \cite{Yao86}, presented in section
\ref{sub:Garbled-Circuit-Method}, along with a supporting compiler
that allows secure functions to be written in a more familiar functional
programming notation. We showed
how \emph{Ordered Binary Decision Diagrams} (OBDD)  can be used to
produce a more efficient protocol for secure evaluation for certain
functions\cite{kruger06}. Function specific protocol design has produced secure protocols
which perform dramatically better than general protocols. Privacy-preserving data mining (PPDM) has been a major application driving
such research \cite{verykios04stateart}. Other protocols have been
developed for various classes of functions such as polynomial evaluation
\cite{naor99otope} and string alignment algorithms such as edit distance
\cite{kruger07}.  Moore's law has been a factor as well which benefits privacy-preserving protocols.
We have shown that in many
cases, the computation requirements of general protocols
can be adequate for practical use when performed on modern
CPUs \cite{kruger06,kruger10}.

We have researched ways to improve the efficiency and practicality
of privacy preserving protocols. Our work has investigated finding
efficient protocols for specific classes of functions; for example
one study analyzes several designs of a $k$-means clustering algorithm
\cite{kruger05}, and another discusses ways to design efficient protocols
for many kinds of dynamic programming problems \cite{kruger07}. We
have also investigated the use of alternate circuit representations
using OBDDs to improve the performance of general purpose protocols
and showed that they can be beneficial for certain functions \cite{kruger06}.
These works are discussed in section \ref{sec:Techniques}.
We also demonstrated a practical application of SFE as a new approach
to solving classic security problems with password authentication, using
SFE to model the hashing functions used in traditional password schemes.
\cite{kruger10}

Our thesis statement is this:  SFE can be used for practical purposes today,
enabling privacy-preserving computation to thrive in today's distributed
world. In the rest of this document, we will demonstrate this thesis through
practical examples of the use of SFE.  We will show how traditional algorithms
can be adapted to preserve privacy, such as in the case of K-means clustering
and privacy preserving genomic algorithms.  We will show how cryptographic
primitives suitable for real-time use can be developed by presenting an
oblivious transfer protocol based on the modular square roots.  We will
also show how traditional security problems can be solved using SFE,
by presenting a secure protocol for password authentication with strong
security guarentees and legacy interoperability that is better than other
authentication protocols in common use.

