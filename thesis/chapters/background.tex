
\section{Background and Related Work}


\subsection{Primitives \label{sub:Primitives}}


\subsubsection{Oblivious Transfer}

Oblivious transfer is a protocol originally proposed by Rabin \cite{Rabin81}.
Informally, a 1-out-of-n oblivious transfer, denoted as $OT_{n}^{1}$,
is a protocol between two parties, the Chooser and the Sender. The
Sender's inputs into the protocol are $n$ values $v_{1},...,v_{n}$.
The Chooser's input is an index $i$ such that $1\le i\le n$. As
a result of the protocol, the Chooser receives $v_{i}$, but does
not learn any additional information about the rest of the Sender's
values. The Sender learns nothing. 

The Naor-Pinkas OT protocol \cite{NaorPinkas99}, based on discrete
logarithms, is considered to be the most efficient OT protocol for
practical use today. The performance characteristics of this protocol
are discussed in section \ref{sub:Comparison-with-Naor-Pinkas}.


\subsubsection{Homomorphic Encryption}

Homomorphic Encryption is a class of public key encryption algorithms
that satisfies a homomorphism property. An additive homomorphic cipher
satisfies $E(a+b)=E(a)\oplus E(b)$ where $\oplus$ is an efficiently
computable operator that requires no secret information. Similarly,
a multiplicative homomorphic cipher satisfies $E(ab)=E(a)\otimes E(b)$.
Some of the most famous public key ciphers have the multiplicative
homomorphic property, including the Elgamal cipher \cite{elgamal85}
and the RSA cipher \cite{rivest83rsa}. The homomorphic properties
have traditionally been considered undesirable for general purpose
cryptography \cite{jmsw02}. %
\begin{comment}
mention Cramer-Shoup?
\end{comment}
{}Specifically, the malleability of ciphertexts can allow the adversary
to violate integrity constraints, and also make such ciphers insecure
against %
\begin{comment}
 because the homomorphic structure aids in cryptanalysis and allows
encrypted messages to be modified, violating integrity constraints.
\cite{jmsw02}. This leads to insecurity against
\end{comment}
{}\emph{adaptive chosen ciphertext} (CCA2) attacks \cite{bleichenbacher98chosen}.
However, homomorphic encryption schemes have also found use in novel
cryptographic applications such as secure voting \cite{benaloh94}. 
\begin{description}
\item [{Semantically~secure~additive~homomorphic~encryption.}] This
is a cipher which satisfies certain properties that are useful in
SFE protocols. Let $(G,E,D,M)$ be a public-key encryption scheme.
$E_{e}(m)$ and $D_{d}(c)$ are the encryption and decryption functions
for plaintext $m$ and ciphertext $c$, with respect to a public/private
key pair ($e,d)$. $G$ is a key generation function that can be used
to randomly generate $(e,d)$ pairs, and $M$ is the message space
respectively. \end{description}
\begin{itemize}
\item The encryption scheme is semantically secure \cite{Goldwasser:Micali}.
Informally, this means that the ciphertext leaks no useful information
about the plaintext even if the attacker has previously observed many
plaintext-ciphertext pairs on plaintexts of his choice. Formally,
let $P(m)$ be any efficently computable Boolean predicate $P(m)$.
WLOG, assume that $Pr[P(m)\mbox{ is true}]=p\ge0.5$ if $m$ is chosen
uniformly from $M$. For any $m$, the adversary, given $E(m)$ must
not be able to correctly compute $P(m)$ with probability $p+\epsilon$,
unless $\epsilon$ is negligible. With any semantically secure encryption
scheme, encrypting the same message twice will yield different ciphertexts
with high probability, so $E(m)$ must be a randomized one-to-many
function representing a set of possible ciphertexts that can be obtained
by encrypting $m$. Naturally, if $m_{1}\neq m_{2}$, then $E(m_{1})\cap E(m_{2})=\emptyset$
\item There exists a computable function $f$, computable without the private
key or other secret information, such that for all messages $m_{1}$,
$m_{2}$, and $c_{1}\in E(m_{1})$, $c_{2}\in E(m_{2})$, the following
property holds:\\
$f\left(c_{1},c_{2}\right)\in E(m_{1}+m_{2})$
\item There exists a computable function $g$ such that for all $m_{1}\in M$
and $\alpha\in M$, $c_{1}\in E(m)$ implies that $g(c_{1},\alpha)\in E(\alpha m_{1})$.
In addition, $g$ must be computable without using the private key
or other secret information. This property follows automatically from
the previous requirement, because it is always possible to define
$g$ in terms of $O(\log\alpha)$ invocations of the function $f$.
\end{itemize}
There are several encryption schemes that satisfy these properties,
of which Paillier's encryption scheme, based on composite residue
classes, is the most widely used \cite{Paillier99}. In the Paillier
cryptosystem, the message space is $m<n$, where $n=pq$ for $p$
and $q$ prime. The ciphertext space is $E(m)<n^{2}$. Let $g<n^{2}$
such that $g$ has order $n\alpha$. Using the public key $(g,n)$,
the encryption function $E(m)=g^{m}r^{n}\left(\mbox{mod }n^{2}\right)$,
for a random $r<n$. Using the private key $\lambda=\mbox{lcm}(p-1,q-1)$,
the decryption function for ciphertext $c$ is $m=\frac{L\left(c^{\lambda}\mbox{ mod }n^{2}\right)}{L\left(g^{\lambda}\mbox{ mod }n^{2}\right)}\mbox{ mod }n$
where $L(u)=\frac{u-1}{n}$ is a well defined function for $u\equiv1\;(\mbox{mod }n)$.
Notice that $E(m_{1})\cdot E(m_{2})=g^{m_{1}}r_{1}^{n}g^{m_{2}}r_{2}^{n}=g^{m_{1}+m_{2}}(r_{1}r_{2})^{n}\in E(m_{1}+m_{2})$,
which satisfies the additive homomorphic property. Further details
can be found in \cite{Paillier99}.


\subsection{Secure Function Evaluation}

One of the fundamental cryptographic primitives for designing privacy-preserving
protocols is \textit{secure function evaluation (SFE)}. A protocol
for SFE enables two parties $A$ and $B$ with inputs $x$ and $y$
respectively to jointly compute a function $f(x,y)$ while preserving
the privacy of the two parties' respective inputs. At the end of the
protocol, party $A$ only knows its input $x$ and the value of the
function $f(x,y)$, and a similar condition holds for $B$. It was
proved by Yao \cite{Yao86} and Goldreich, Micali, and Wigderson \cite{GMW87}
that for a polynomially computable function $f$, there exists protocols
for securely evaluating $f$ that executes in polynomial time. Both
proofs are constructive, and provide a method for transforming a Boolean
circuit description of the function $f$ into a protocol for secure
evaluation of $f$. These protocols are summarized here.


\subsubsection{Garbled Circuit Method \label{sub:Garbled-Circuit-Method}}

Consider any Boolean circuit $C$, and two parties, Alice and Bob,
who wish to evaluate $C$ on their respective inputs $x$ and $y$.
In Yao's {}``garbled circuits'' method \cite{Yao86}, Alice securely
transforms the circuit so that Bob can evaluate it obliviously, i.e.,
without learning Alice's inputs or the values on any internal circuit
wire except the output wires. The steps are as follows:
\begin{enumerate}
\item Alice generates two random keys $k_{i,0}$ and $k_{i,1}$ for each
circuit wire $i$, one representing $0$ on that wire, the other representing
$1$. For all wires in the circuit except input wires, the truth table
for the corresponding Boolean gate is encrypted. If $g(x,y)$ is a
gate with input wires $j$ and $l$, and output wire $i$, then the
truth table value for $g(x,y)$ is encoded as $E_{k_{j,x}}\left(E_{k_{l,y}}\left(k_{i,g(x,y)}\right)\right)$.
Here, $k_{j,x}$ is the encryption key for value $x$ of wire $j$,
and similarly for $k_{l,j}$. $k_{i,g(x,y)}$ is the encryption key
for the output wire of $g$ with value $g(x,y)$ The four encrypted
values representing $g(0,0)$, $g(0,1)$, $g(1,0)$, and $g(1,1)$
fully specify the gate $g$. Alice sends the garbled circuit to Bob.
Computation of the garbled circuit does not depend on input values
and can be performed in advance. However, the same garbled circuit
must not be used more than once, or Alice's privacy may be violated.
\item Alice sends the keys corresponding to her own input wires to Bob.
Bob obtains the keys corresponding to his input wires from Alice using
an $OT_{2}^{1}$ protocol. For each of Bob's input wires, Bob acts
as the chooser using his circuit input bit as his input into $OT_{2}^{1}$
, and Alice acts as the sender with the two wire keys for that wire
as her inputs into $OT_{2}^{1}$ .
\item Bob evaluates the circuit. Because of the way that the garbled circuit
is constructed, Bob, having one wire key for each gate input, can
decrypt exactly one row of the garbled truth table and obtain the
key encoding the value of the output wire. Yao's protocol maintains
the invariant that for every circuit wire, Bob learns exactly one
wire key. Because wire keys are random and the mapping from wire keys
to values is not known to Bob (except for the wire keys corresponding
to his own inputs), this does not leak any information about actual
wire values. The circuit can thus be evaluated obliviously. A complete
description of Yao's method and security proofs can be found in \cite{Goldreich:vol2}.
\end{enumerate}

\subsubsection{Secure Computation With Random Shares}

\cite{GMW87} presents a protocol for securely evaluating circuits
known as \emph{secure computation with shares} (SCWS). This protocol
maintains the invariant that, for every circuit wire $w$, Alice learns
a random value $s$ and Bob learns $b_{w}\oplus s$, where $b_{w}$
is the bit value of the wire. Therefore, Alice's and Bob's shares
add up to $b_{w}$, but because the shares are random, neither party
knows the actual wire value. For each output wire of the circuit,
Alice and Bob combine their shares to reconstruct the circuit output.
Suppose $g(x,y)$ is a gate, $x$ and $y$ are the input wires to
the $g$ and $x_{a}\oplus x_{b}=x$ and $y_{a}\oplus y_{b}=y$ are
Alice and Bob's shares of $x$ and $y$. The following steps will
securely evaluate the gate:
\begin{enumerate}
\item Alice selects a random bit $z_{a}$ 
\item Alice constructs a quadruple $\left(g(x_{a},y_{a})\oplus z_{a},\, g(x_{a},1-y_{a})\oplus z_{a},\, g(1-x_{a},y_{a})\oplus z_{a},\, g(1-x_{a},1-y_{a})\oplus z_{a}\right)$. 
\item Using an $OT_{4}^{1}$ protocol, Bob selects the bit from Alice's
quadruple with index $s=2x_{b}+y_{b}$. The value received by Bob
is $z_{b}=g(x_{a}\oplus x_{b},y_{a}\oplus y_{b})\oplus z_{a}=g(x,y)\oplus z_{a}$. 
\end{enumerate}
At the beginning of the evaluation, Alice sets her share of the input
wires to her input values, and her share of Bob's input wires to $0$,
and vice versa for Bob. Each gate $g$ may be evaluated after Alice
and Bob have computed their shares of the gate's input wires. Thus,
by repeated applying the above steps, the entire circuit can be evaluated
starting from the inputs, and progressing gate by gate until the output.
Further details and security proofs are presented in \cite{Goldreich:vol2}.

In practice, the garbled circuit method is more commonly used, because
it is more efficient. Then garbled circuit method requires only a
single transfer of data from Alice to Bob, followed by an $OT_{2}^{1}$
for each the $|B|$ values representing Bob's inputs. These OTs can
be combined into a single parallel OT. Then Bob obliviously evaluates
the entire circuit on his own, and sends the output keys of Alice's
outputs back to her. In contrast, the SCWS method requires an $OT_{4}^{1}$
for each gate. This will require at least $depth(C)$ distinct rounds
of the OT, where $depth(C)$ is the maximum number of gates along
any path from an input to an output. The increased number of OTs,
combined with the increased number of rounds needed to execute them,
makes the SCWS evaluation protocol primarily of theoretical interest.
However, the SCWS principle can be emulated with the Yao protocol,
by explicitly including extra gates in the circuit to combine and
split the share values. 


\subsection{Implementations}

In recent years, there have been implementations of SFE undertaken
by researchers to design secure multiparty protocols. In the past,
SFE was considered a theoretical topic too expensive for practical
use, but the convergence of ubiquitous communication using the Internet,
more efficient cryptographic primitives, and the exponentially increasing
availability of processing power and network bandwidth are making
SFE an area of increasingly significant practical value.


\subsubsection{Fairplay}

Fairplay \cite{Fairplay} is an example of an SFE implementation designed
to enable wider application of SFE. Fairplay is the first system,
designed to be practical, that attempts to make SFE using Yao's protocol
available to a wider audience. It consists of a compiler that takes
as input a function $f$ defined using a procedural language called
\emph{Secure Function Description Language} (SFDL), and outputs a
Boolean circuit to evaluate $f$ using a description language called
\emph{Secure Hardware Description Language} (SHDL). Fairplay also
includes an implementation of the two party Yao protocol which securely
evaluates an SHDL function. \cite{Fairplay} provides the first empirical
measurements from an implementation of the Yao protocol.


\subsubsection{Application specific}

Fairplay showed that the classic protocol for SFE is still quite expensive
for all but the simplest circuits. There has been much research effort
in designing more efficient privacy-preserving protocols for many
problems of interest. In \cite{Reiter:CCS:2003}, a compiler was implemented
for generating secure two-party protocols for a restricted class of
functions built from modular arithmetic. The particular design was
motivated by the desire to build efficient secure protocols such as
signature schemes and threshold cryptography. Secure protocols have
been implemented for many problems such as auctions \cite{NPS99},
set intersection \cite{FNP04}, and conducting surveys \cite{FNP04}.
A particularly important application of secure computation is discussed
in the next section.


\subsection{Privacy Preserving Data Mining }

Initial focus in this area was on construction of decision trees from
distributed data sets \cite{Agrawal-Srikant,Lindell-Pinkas}. There
is also a significant body of research on privacy-preserving mining
of association rules \cite{Gehrke:2002,RizviHarista,VaidyaClifton:2002}.
In general, there are two approaches for designing privacy-preserving
data mining algorithms. The first approach is to use transformations
to perturb the data set before the algorithm is applied, by replacing
sensitive data with random unique identifiers. This approach for designing
privacy-preserving algorithms is taken by several researchers \cite{Klusch,MeruguGhosh,Oliveira}.
However, this approach suffers from the lack of formal security guarantee,
and has been shown to be vulnerable to data correlation attacks \cite{Malin04}.
Secure multiparty computation is the basis of the other approach.
A survey of such techniques is presented in \cite{PinkasCryptoPPDM02}.
This approach is the primary topic discussed here.


\subsection{Threat Models\label{sub:Threat-Models}}

In the {}``malicious'' threat model, a badly behaving party is free
to use any available methods to thwart the computation , including
sending false or inconsistent messages at any step of the protocol.
The malicious threat model naturally characterizes the malicious behavior
that a secure protocol would need to protect against. If a protocol
is shown to be secure in the malicious threat model, then we can reasonably
assume that a malicious party or interloper will not be able to learn
any private information by attacking the protocol.

In the {}``semi-honest'' threat model, also known as {}``honest
but curious'', or {}``passive'', a party to the computation is
assumed to behave correctly and follow the protocol as prescribed.
However, the party also runs additional probabilistic polynomially
bounded computation on the side in order to learn information to which
he is not entitled. A security proof using the semi-honest threat
model implies that the protocol as designed does not {}``leak''
information. The semi-honest model is an important theoretical tool
despite the fact that it is weaker and does not capture the full range
of malicious behaviors we would expect of an adversary. This is because
a protocol that has been proven secure in the semi-honest model can
be extended in an automated way, using a protocol {}``compiler'',
to a more secure protocol that is secure in the malicious model \cite{GMW87}.
Essentially, the protcol compiler inserts additional steps into the
protocol to force the parties to prove to one another their faithful
adherence to the protocol. The semi-honest model may itself be a realistic
model in certain cases, for example, when the parties communicating
need to preserve privacy of data from one another, but also have a
sufficient trust relationship not to intentionally cheat.

%
\begin{comment}
\bibliographystyle{plain}
\bibliography{privacy,somesh,crypto}

\end{comment}
{}
